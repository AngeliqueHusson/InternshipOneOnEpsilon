three sloppily written extremely low resolution brain trouble three want take moment appreciate crazy brains effortlessly mean also recognizable three even though specific value pix el different one image next particular light sensitive cell eye firing see three different firing see three something crazy smart visual cortex represent ing idea time image distinct told hey sit write program take grid like output single number telling digit task goes comically trivial dauntingly difficult unless living rock think hardly need motivate relevance importance machine learning neural present future want show neural network actually assuming background help visualize buzz word piece math hope come away feeling like structure feel like know mean read hear neural network quote unquote learning video going devoted structure component following one going tackle learning going put together neural network learn recognize hand written somewhat classic example topic happy stick status quo end two video want point couple good resource learn load code play computer many many variant neural recent sort boom research towards two introductory video going look plain vanilla form added kind necessary prerequisite understanding powerful modern variant trust still plenty complexity us wrap mind around even form learn recognize hand written pretty cool thing computer able time see fall short couple might name suggest neural inspired brain let break neuron sense linked together right say neuron want think thing hold number specifically number really example network start bunch neuron corresponding times pix els input image neuron total one hold number represent gray scale value corresponding black pix els white number inside neuron cal led activation image might mind neuron lit activation high number neuron make first layer network jump ing last layer ten neuron represent ing one activation neuron number zero much system given image correspond given digit also couple cal led hidden time giant question mark earth process going network chose two hidden one neuron admittedly kind arbitrary choice honest chose two based want motivate structure moment well nice number fit screen practice lot room experiment specific structure way network operate activation one layer determine activation next layer course heart network information process ing mechanism comes exactly one layer bring activation next layer meant loosely analogous biological neuron group neuron firing cause certain network showing already trained recognize let show mean mean feed image lighting neuron input layer according brightness pix el image pattern activation cause specific pattern next layer cause pattern one finally give pattern output layer neuron output layer network choice speak digit image represent jump ing math one layer influence next training works let talk even reasonable expect layered structure like behave intelligently expect ing best hope middle might well recognize piece together various component nine loop top line right also loop top paired another loop lowa basically break three specific thing like perfect world might hope neuron one sub time feed image say loop top like specific neuron whose activation going close one n mean specific loop pix els hope would generally loopy pattern towards top set neuron way going third layer last one require learning combination sub component correspond course kick problem road would recognize sub component even learn right sub component still n even tal ked one layer influence next run one loop also break reasonable way would first recognize various little edge make similarly long line like kind might see really long edge maybe think certain pattern several smaller maybe hope neuron second layer various relevant little image like one comes light around eight ten specific little turn light neuron associated upper loop long vertical line light neuron associated nine whether final network actually another question one come back see train network hope might sort goal layered structure like moreover imagine able detect edge pattern like would really useful image recognition task sand even beyond image recognition sort intelligent thing might want break speech example involve taking raw audio distinct combine make certain combine form word combine make phrase abstract thought getting back actually works picture right designing exactly activation one layer might determine activation next goal mechanism could conceivably combine pix els edge pattern pattern zoom one specific example let say hope one particular neuron second layer pick whether image edge region question hand parameter network dial able tweak expressive enough potentially capture pattern pix el pattern pattern several edge make loop thing well assign weight one connection neuron neuron first layer weight take activation first layer compute weighted sum according weight find helpful think weight organized little grid going use green pix els indicate positive weight red pix els indicate negative brightness pix el loose depiction weight value made weight associated almost pix els zero except positive weight region care taking weighted sum pix el value really amount value pix el region care really want pick whether edge might negative surrounding sum middle pix els bright surrounding pix els compute weighted sum like might come number network want activation value common thing pump weighted sum function squish es real number line range anda common function cal led sigmoid function also known logistic curve basically negative input end close zero positive input end close steadily increase around input activation neuron basically measure positive relevant weighted sum maybe want neuron light weighted sum bigger want active sum bigger say want bias inactive add number like negative weighted sum plugging sigmoid function additional number cal led bias weight tell pix el pattern neuron second layer high weighted sum needs neuron start getting meaningfully active one neuron layer going connected pix els neuron first layer one connection weight associated also one bias number add weighted sum squish ing sigmoid lot think hidden layer total times weight along connection first layer second connection bunch weight bias es associated said done network almost total weight dial turned make network behave different ways talk learning getting computer find valid setting many many actually solve problem thought experiment fun kind horrify ing imagine sitting setting weight bias es hand purposefully tweak ing second layer pick edge third layer pick pattern personally find satisfying rather reading network total black box network n perform way anticipate built little bit relationship weight bias es actually mean starting place change structure improve network work might expect digging weight bias es good way challenge assumption really expose full space way actual function little cumbersome write n think let show compact way connection see choose read neural activation one layer column vector organize weight matrix row connection one layer particular neuron next layer mean taking weighted sum activation first layer according weight correspond one term matrix vector product everything left hereby way much machine learning comes good grasp linear algebra want nice visual understanding matrices matrix vector multiplication mean take look series linear algebra especially chapter three back expression instead talking bias one value independently represent bias es vector entire vector previous matrix vector product final step rap sigmoid around outside supposed represent going apply sigmoid function specific component resulting vector inside write weight matrix vector symbol communicate full transition activation one layer next extremely tight neat little expression make relevant code lot simpler lot faster since many optimize heck matrix multiplication remember ear lier said neuron simply thing hold number swell course specific hold depend image feed actually accurate think neuron function one take neuron previous layer spit number zero one really entire network function one take input spit ten output absurdly complicated function one involve thirteen thousand parameter form weight bias es pick certain pattern many matrix vector product sigmoid squish evocation function function nonetheless way kind reassuring look mean simpler hope would could take challenge take challenge network learn appropriate weight bias es looking data oh show next video also dig little particular network seeing really point suppose say subscribe stay notified video new video come realistically n actually receive notification tube maybe honestly say subscribe neural underlie algorithm prime believe want see content channel get anyway stay posted much everyone supporting video little slow progress probability series summer jump ing back project patron look update thereto close thing work theoretical side deep learning currently works venture capital firm cal led amplify kindly provided video one thing think quickly bring sigmoid function understand early used squish relevant weighted sum interval zero one know kind motivate biological analogy neuron either inactive active exactly relatively modern actually use sigmoid kind old school right yeah seem much easier train rel u really stand rectified linear unit yes kind function taking given explaining video sort motivate think partially biological analogy would either activate certain threshold would identity function would activate zero kind sigmoid n help training difficult train point people tried rel u work well incredibly deep neural right thank background amplify partner early stage v c invest technical building next generation ai someone know ever thought starting company someday working early stage one right amplify folk would love hear even set specific video feel free reach neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter neural network deep learning chapter
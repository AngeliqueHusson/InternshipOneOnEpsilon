Around a hundred years ago something really exciting was happeningAn age old philosophical question what is the limitof knowledge collided with the modern mathematical onecan knowledge be mechanisedAnd this gave birth to a new fieldComputer sciencethe science of computationThe dream of mechanising human knowledgewas inspired by developments over 300 years agoduring the early stages of the industrial revolutionFactories were being developed as industrialists began to explore mass productionand the mechanisation of labourgradually machines were designed to replicate human actionbut replicating human mental processesremained the stuff of dreamsAnd this began to change with the development of machines that could addmultiply and eventually make decisionsAt first even the most advanced machines were limited toone specific taskif you needed something else doneyou had to build a new machineHowever around two hundred years agoa great industrialist thinker Charles Babbagewas dreaming of a general symbolic machineone that could answer complex questionsby breaking them down into smaller questions of logic & arithmeticand essentially braiding them togetherHis final dream was never realized buthis driving question remainedwas it possible to build a general machinethat could answer any questionNow by the 1900s mathematicians and philosopherswere posing this question in different waysmathematicians askedwhat are mechanical machines capable ofhow powerful could they bewhile philosophers askedwhat are the limitations of mechanical machineswhat will machines never doAnd in 1936 Alan Turing bridged this dividewith a paper which revolutionized our understandingabout what machines can and cannot doHe outlined blueprints for what he called a universal machinea machine that could answer anythingthat was answerablePart of his great insight was thatthe power of the universal machine would alwaysreside in the instructions it followedlater known as softwarenot the physical design of the machineor hardwareAnd using a simple languagehis machine would run any instructions that you could imagineAnd the year after Turing's paper a young Claude Shannoncompleted a master's thesis describing a clever insighthe had about telephone relaysHe realised he could arrange electrical switchesin various ways to perform the fundamental operations of logic automaticallyusing electricitySuddenly it was practically possible to build the universal computerpowered by electrical clocks that buzzed away at near the speed of lightand followed any instructions you provideIn the decades to follow computing machines grew and their speedof operation & memory capacitySuddenly many hard questions humans faced became easy or very practicalfor computers to answer quicklyBut deeper problems emergedThere seemed to be a growing set of seemingly easy problemssuch as is a given number primethat were computable on our machinesbut took so long when the questions were largesuch as is 140 trillion trillion trillion + 1 primethat it could take thousands or even millions of yearsfor the computer to give you an answeror haltSo these problems were practically impossible to solvethink of these as hard problemsand people considered drawing a line in the sand between problems that were easypractical to solveand problems that were hardpractically impossible to solveAnd the attempt to precisely define this divisionof easy and hard, practical and impractical problemsleads to the most important unsolved question in computer science todaywhat makes hard problems hard ?Is it a result of some underlying mathematical patternor is the perception of hardness merely an illusion ?will new insights make these hard problems easy ?And this question is just not an intellectual curiositythe backbone of the internet depends on a set of problemsbeing out of reach or practically impossiblefor our machinesBut to begin we must goway back in timeand revisit the mythology of ancient oraclesfirst of all explore what knowledge isand what it means to thinkor to compute